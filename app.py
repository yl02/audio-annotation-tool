import streamlit as st
import os
import librosa
import numpy as np
import json
from utils.audio_processing import load_audio, plot_waveform
from utils.annotation_utils import save_annotations, load_annotations

# è®¾ç½® Streamlit é¡µé¢
st.set_page_config(page_title="éŸ³ä¹éŸ³é¢‘æ ‡æ³¨å·¥å…·", layout="wide")
st.title("ğŸµ éŸ³ä¹éŸ³é¢‘æ ‡æ³¨å·¥å…·")

# ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
uploaded_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type=["mp3", "wav"])
if uploaded_file is not None:
    file_path = f"assets/{uploaded_file.name}"
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.audio(file_path, format="audio/mp3")

    # åŠ è½½éŸ³é¢‘å¹¶ç»˜åˆ¶æ³¢å½¢
    y, sr = load_audio(file_path)
    waveform_plot = plot_waveform(y, sr)
    st.image(waveform_plot, caption="éŸ³é¢‘æ³¢å½¢")

    # åŠ è½½æ ‡æ³¨
    annotations = load_annotations()

    # æ˜¾ç¤ºç°æœ‰æ ‡æ³¨ä¿¡æ¯
    title = st.text_input("æ›²ç›®åç§°", annotations.get("title", ""))
    artist = st.text_input("è‰ºæœ¯å®¶", annotations.get("artist", ""))
    emotion = st.selectbox("æƒ…æ„Ÿæ ‡ç­¾", ["Happy", "Sad", "Angry"], index=0)

    # å…³é”®æ—¶é—´ç‚¹æ ‡æ³¨
    segments = st.text_area("æ ‡æ³¨å…³é”®æ®µè½ï¼ˆæ ¼å¼ï¼šæ—¶é—´,æ ‡ç­¾ï¼‰", "30,å‰¯æ­Œ\n60,ä¹å™¨ç‹¬å¥")
    segment_list = [{"time": int(line.split(",")[0]), "label": line.split(",")[1]} for line in segments.split("\n")]

    # ä¿å­˜æ ‡æ³¨
    if st.button("ä¿å­˜æ ‡æ³¨"):
        annotation_data = {
            "title": title,
            "artist": artist,
            "segments": segment_list,
            "emotion": emotion
        }
        save_annotations(annotation_data)
        st.success("æ ‡æ³¨æ•°æ®å·²ä¿å­˜ï¼")